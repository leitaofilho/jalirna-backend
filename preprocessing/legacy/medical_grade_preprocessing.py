#!/usr/bin/env python3
"""
Pipeline de Pr√©-processamento de Grau M√©dico para DRC
Mant√©m TODAS as 6 classes cr√≠ticas + Predi√ß√£o multi-tarefa (CREATININA, TFG, Classifica√ß√£o)
Inclui visualiza√ß√µes detalhadas ANTES/DEPOIS do pr√©-processamento
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder
from sklearn.model_selection import StratifiedKFold
from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE
from imblearn.under_sampling import RandomUnderSampler, TomekLinks
from imblearn.combine import SMOTEENN, SMOTETomek
from scipy import stats
from collections import Counter
import joblib
import warnings
import os
from datetime import datetime
warnings.filterwarnings('ignore')

class MedicalGradeDRCPreprocessor:
    """
    Pipeline de pr√©-processamento de grau m√©dico para DRC
    - Mant√©m TODAS as 6 classes de TFG_Classification
    - Suporte para 3 tarefas: CREATININA (regress√£o), TFG (regress√£o), Classifica√ß√£o
    - Visualiza√ß√µes detalhadas antes/depois
    """
    
    def __init__(self, random_state=42):
        self.random_state = random_state
        
        # Componentes do pipeline
        self.label_encoders = {}
        self.scaler = None
        self.classification_balancer = None
        self.target_encoder = None
        
        # Metadados
        self.feature_names = None
        self.target_names = None
        self.is_fitted = False
        self.preprocessing_report = {}
        
        # Features de entrada (13 do DRCForm)
        self.input_features = [
            'IDADE', 'SEXO', 'COR', 'COR 2', 'IMC', 'CC', 'RCQ',
            'PAS', 'PAD', 'Fuma?', 'Realiza exerc√≠cio?', 'Bebe?', 'DM', 'HAS'
        ]
        
        # Vari√°veis alvo
        self.target_variables = ['CREATININA', 'TFG', 'TFG_Classification']
        
        # Mapeamento de classes TFG
        self.tfg_class_mapping = {
            'G1 (normal ou aumentada)': 0,
            'G2 (levemente reduzida)': 1,
            'G3a (redu√ß√£o leve a moderada)': 2,
            'G3b (redu√ß√£o moderada a grave)': 3,
            'G4 (gravemente reduzida)': 4,
            'G5 (insufici√™ncia renal)': 5
        }
    
    def analyze_initial_state(self, df):
        """
        An√°lise detalhada do estado INICIAL dos dados
        """
        print("\n" + "="*70)
        print("AN√ÅLISE DO ESTADO INICIAL DOS DADOS")
        print("="*70)
        
        analysis = {
            'timestamp': datetime.now().isoformat(),
            'dataset_shape': df.shape,
            'missing_data': {},
            'data_types': {},
            'target_analysis': {},
            'clinical_validation': {},
            'imbalance_analysis': {}
        }
        
        # 1. Dados faltantes
        print("\n1. DADOS FALTANTES:")
        missing_data = df.isnull().sum()
        missing_pct = (missing_data / len(df)) * 100
        
        has_missing = False
        for col in df.columns:
            if missing_data[col] > 0:
                analysis['missing_data'][col] = {
                    'count': int(missing_data[col]),
                    'percentage': float(missing_pct[col])
                }
                print(f"  {col}: {missing_data[col]} ({missing_pct[col]:.1f}%)")
                has_missing = True
        
        if not has_missing:
            print("  ‚úÖ Nenhum dado faltante encontrado")
        
        # 2. An√°lise das vari√°veis alvo
        print("\n2. AN√ÅLISE DAS VARI√ÅVEIS ALVO:")
        
        # CREATININA
        if 'CREATININA' in df.columns:
            # Verificar formato
            has_comma = df['CREATININA'].astype(str).str.contains(',').any()
            print(f"  CREATININA:")
            print(f"    Formato com v√≠rgula: {'Sim' if has_comma else 'N√£o'}")
            
            if has_comma:
                creat_numeric = pd.to_numeric(
                    df['CREATININA'].astype(str).str.replace(',', '.'), 
                    errors='coerce'
                )
            else:
                creat_numeric = pd.to_numeric(df['CREATININA'], errors='coerce')
            
            analysis['target_analysis']['creatinina'] = {
                'min': float(creat_numeric.min()),
                'max': float(creat_numeric.max()),
                'mean': float(creat_numeric.mean()),
                'std': float(creat_numeric.std()),
                'has_comma_format': has_comma
            }
            
            print(f"    Range: {creat_numeric.min():.2f} - {creat_numeric.max():.2f} mg/dL")
            print(f"    M√©dia: {creat_numeric.mean():.2f} ¬± {creat_numeric.std():.2f}")
        
        # TFG
        if 'TFG' in df.columns:
            tfg_data = df['TFG'].dropna()
            analysis['target_analysis']['tfg'] = {
                'min': float(tfg_data.min()),
                'max': float(tfg_data.max()),
                'mean': float(tfg_data.mean()),
                'std': float(tfg_data.std())
            }
            
            print(f"  TFG:")
            print(f"    Range: {tfg_data.min():.1f} - {tfg_data.max():.1f} mL/min/1.73m¬≤")
            print(f"    M√©dia: {tfg_data.mean():.1f} ¬± {tfg_data.std():.1f}")
        
        # TFG_Classification
        if 'TFG_Classification' in df.columns:
            class_counts = df['TFG_Classification'].value_counts().sort_index()
            total_samples = len(df)
            
            print(f"  TFG_Classification:")
            analysis['target_analysis']['classification'] = {}
            
            for class_name, count in class_counts.items():
                pct = (count / total_samples) * 100
                analysis['target_analysis']['classification'][class_name] = {
                    'count': int(count),
                    'percentage': float(pct)
                }
                print(f"    {class_name}: {count} ({pct:.1f}%)")
            
            # An√°lise de desbalanceamento
            majority_class = class_counts.max()
            minority_class = class_counts.min()
            imbalance_ratio = majority_class / minority_class
            
            # Classes cr√≠ticas
            critical_classes = class_counts[class_counts < 10]
            
            analysis['imbalance_analysis'] = {
                'total_classes': len(class_counts),
                'majority_class_size': int(majority_class),
                'minority_class_size': int(minority_class),
                'imbalance_ratio': float(imbalance_ratio),
                'critical_classes': len(critical_classes),
                'critical_class_details': dict(critical_classes)
            }
            
            print(f"\n3. AN√ÅLISE DE DESBALANCEAMENTO:")
            print(f"  Raz√£o de desbalanceamento: {imbalance_ratio:.1f}:1")
            print(f"  Classes com <10 amostras: {len(critical_classes)}")
            if len(critical_classes) > 0:
                print(f"  Classes cr√≠ticas: {dict(critical_classes)}")
        
        # 4. Valida√ß√£o cl√≠nica
        print(f"\n4. VALIDA√á√ÉO CL√çNICA:")
        self._validate_clinical_ranges(df, analysis)
        
        self.preprocessing_report['initial_analysis'] = analysis
        return analysis
    
    def _validate_clinical_ranges(self, df, analysis):
        """
        Valida ranges cl√≠nicos espec√≠ficos
        """
        clinical_validation = {}
        
        # Creatinina por sexo
        if 'CREATININA' in df.columns and 'SEXO' in df.columns:
            creat_numeric = pd.to_numeric(
                df['CREATININA'].astype(str).str.replace(',', '.'), 
                errors='coerce'
            )
            
            if 'MASCULINO' in df['SEXO'].values:
                male_creat = creat_numeric[df['SEXO'] == 'MASCULINO'].dropna()
                if len(male_creat) > 0:
                    normal_male = ((male_creat >= 0.7) & (male_creat <= 1.2)).mean() * 100
                    clinical_validation['creatinina_normal_male_pct'] = float(normal_male)
                    print(f"  Creatinina normal (homens): {normal_male:.1f}%")
            
            if 'FEMININO' in df['SEXO'].values:
                female_creat = creat_numeric[df['SEXO'] == 'FEMININO'].dropna()
                if len(female_creat) > 0:
                    normal_female = ((female_creat >= 0.6) & (female_creat <= 1.1)).mean() * 100
                    clinical_validation['creatinina_normal_female_pct'] = float(normal_female)
                    print(f"  Creatinina normal (mulheres): {normal_female:.1f}%")
        
        # TFG por est√°gios
        if 'TFG' in df.columns:
            tfg_data = df['TFG'].dropna()
            
            stages = {
                'G1 (‚â•90)': (tfg_data >= 90).sum(),
                'G2 (60-89)': ((tfg_data >= 60) & (tfg_data < 90)).sum(),
                'G3a (30-59)': ((tfg_data >= 30) & (tfg_data < 60)).sum(),
                'G3b (15-29)': ((tfg_data >= 15) & (tfg_data < 30)).sum(),
                'G4+G5 (<15)': (tfg_data < 15).sum()
            }
            
            print("  Distribui√ß√£o TFG por est√°gio cl√≠nico:")
            clinical_validation['tfg_stages'] = {}
            for stage, count in stages.items():
                pct = (count / len(tfg_data)) * 100
                clinical_validation['tfg_stages'][stage] = {
                    'count': int(count),
                    'percentage': float(pct)
                }
                print(f"    {stage}: {count} ({pct:.1f}%)")
        
        analysis['clinical_validation'] = clinical_validation
    
    def create_before_visualizations(self, df, output_dir='plots/preprocessing'):
        """
        Cria visualiza√ß√µes detalhadas do estado ANTES do pr√©-processamento
        """
        print(f"\n" + "="*70)
        print("GERANDO VISUALIZA√á√ïES - ESTADO INICIAL")
        print("="*70)
        
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. An√°lise completa das vari√°veis alvo
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('Estado INICIAL - An√°lise Completa das Vari√°veis Alvo', fontsize=16, fontweight='bold')
        
        # CREATININA
        if 'CREATININA' in df.columns:
            creat_numeric = pd.to_numeric(
                df['CREATININA'].astype(str).str.replace(',', '.'), 
                errors='coerce'
            ).dropna()
            
            axes[0, 0].hist(creat_numeric, bins=20, alpha=0.7, color='lightcoral', edgecolor='black')
            axes[0, 0].axvline(creat_numeric.mean(), color='red', linestyle='--', 
                              label=f'M√©dia: {creat_numeric.mean():.2f}')
            axes[0, 0].axvline(creat_numeric.median(), color='blue', linestyle='--', 
                              label=f'Mediana: {creat_numeric.median():.2f}')
            # Ranges normais
            axes[0, 0].axvspan(0.7, 1.2, alpha=0.2, color='green', label='Normal (M)')
            axes[0, 0].axvspan(0.6, 1.1, alpha=0.2, color='lightgreen', label='Normal (F)')
            axes[0, 0].set_title('Distribui√ß√£o da Creatinina')
            axes[0, 0].set_xlabel('Creatinina (mg/dL)')
            axes[0, 0].set_ylabel('Frequ√™ncia')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
        
        # TFG
        if 'TFG' in df.columns:
            tfg_data = df['TFG'].dropna()
            axes[0, 1].hist(tfg_data, bins=20, alpha=0.7, color='lightblue', edgecolor='black')
            axes[0, 1].axvline(tfg_data.mean(), color='red', linestyle='--', 
                              label=f'M√©dia: {tfg_data.mean():.1f}')
            axes[0, 1].axvline(tfg_data.median(), color='blue', linestyle='--', 
                              label=f'Mediana: {tfg_data.median():.1f}')
            
            # Est√°gios de TFG
            stages = [15, 30, 60, 90]
            colors = ['red', 'orange', 'yellow', 'lightgreen']
            labels = ['G5', 'G4', 'G3', 'G2']
            for stage, color, label in zip(stages, colors, labels):
                axes[0, 1].axvline(stage, color=color, linestyle=':', alpha=0.7, label=f'{label}: {stage}')
            
            axes[0, 1].set_title('Distribui√ß√£o da TFG')
            axes[0, 1].set_xlabel('TFG (mL/min/1.73m¬≤)')
            axes[0, 1].set_ylabel('Frequ√™ncia')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
        
        # TFG_Classification
        if 'TFG_Classification' in df.columns:
            class_counts = df['TFG_Classification'].value_counts().sort_index()
            bars = axes[0, 2].bar(range(len(class_counts)), class_counts.values, 
                                 color='lightgreen', alpha=0.7, edgecolor='black')
            axes[0, 2].set_title('Distribui√ß√£o das Classes TFG')
            axes[0, 2].set_xlabel('Classes')
            axes[0, 2].set_ylabel('N√∫mero de Amostras')
            axes[0, 2].set_xticks(range(len(class_counts)))
            axes[0, 2].set_xticklabels([f'G{i+1}' for i in range(len(class_counts))], rotation=45)
            
            # Adicionar valores nas barras
            for bar, count in zip(bars, class_counts.values):
                axes[0, 2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                               str(count), ha='center', va='bottom')
            axes[0, 2].grid(True, alpha=0.3)
        
        # Correla√ß√£o TFG vs Creatinina
        if 'TFG' in df.columns and 'CREATININA' in df.columns:
            creat_numeric = pd.to_numeric(
                df['CREATININA'].astype(str).str.replace(',', '.'), 
                errors='coerce'
            )
            
            valid_mask = ~(df['TFG'].isna() | creat_numeric.isna())
            if valid_mask.sum() > 0:
                scatter = axes[1, 0].scatter(creat_numeric[valid_mask], df['TFG'][valid_mask], 
                                           alpha=0.6, color='purple')
                
                # Linha de tend√™ncia
                z = np.polyfit(creat_numeric[valid_mask], df['TFG'][valid_mask], 1)
                p = np.poly1d(z)
                axes[1, 0].plot(creat_numeric[valid_mask], p(creat_numeric[valid_mask]), 
                               "r--", alpha=0.8, linewidth=2)
                
                # Correla√ß√£o
                corr = np.corrcoef(creat_numeric[valid_mask], df['TFG'][valid_mask])[0, 1]
                axes[1, 0].set_title(f'TFG vs Creatinina\nCorrela√ß√£o: {corr:.3f}')
                axes[1, 0].set_xlabel('Creatinina (mg/dL)')
                axes[1, 0].set_ylabel('TFG (mL/min/1.73m¬≤)')
                axes[1, 0].grid(True, alpha=0.3)
        
        # An√°lise por sexo
        if 'SEXO' in df.columns and 'TFG_Classification' in df.columns:
            sex_class_crosstab = pd.crosstab(df['SEXO'], df['TFG_Classification'])
            im = axes[1, 1].imshow(sex_class_crosstab.values, cmap='Blues', aspect='auto')
            axes[1, 1].set_title('Distribui√ß√£o Sexo x Classe TFG')
            axes[1, 1].set_xticks(range(len(sex_class_crosstab.columns)))
            axes[1, 1].set_xticklabels([f'G{i+1}' for i in range(len(sex_class_crosstab.columns))], 
                                      rotation=45)
            axes[1, 1].set_yticks(range(len(sex_class_crosstab.index)))
            axes[1, 1].set_yticklabels(sex_class_crosstab.index)
            
            # Adicionar valores nas c√©lulas
            for i in range(len(sex_class_crosstab.index)):
                for j in range(len(sex_class_crosstab.columns)):
                    axes[1, 1].text(j, i, str(sex_class_crosstab.iloc[i, j]),
                                   ha='center', va='center', color='white' if sex_class_crosstab.iloc[i, j] > sex_class_crosstab.values.max()/2 else 'black')
        
        # Log scale para visualizar classes pequenas
        if 'TFG_Classification' in df.columns:
            class_counts = df['TFG_Classification'].value_counts().sort_index()
            bars = axes[1, 2].bar(range(len(class_counts)), class_counts.values, 
                                 color='orange', alpha=0.7, edgecolor='black')
            axes[1, 2].set_yscale('log')
            axes[1, 2].set_title('Classes TFG (Escala Log)')
            axes[1, 2].set_xlabel('Classes')
            axes[1, 2].set_ylabel('N√∫mero de Amostras (log)')
            axes[1, 2].set_xticks(range(len(class_counts)))
            axes[1, 2].set_xticklabels([f'G{i+1}' for i in range(len(class_counts))], rotation=45)
            
            # Destacar classes cr√≠ticas
            for i, (bar, count) in enumerate(zip(bars, class_counts.values)):
                if count < 10:
                    bar.set_color('red')
                    bar.set_alpha(0.8)
                axes[1, 2].text(bar.get_x() + bar.get_width()/2, bar.get_height() * 1.1,
                               str(count), ha='center', va='bottom', fontweight='bold')
            axes[1, 2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f'{output_dir}/01_initial_state_complete.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"‚úÖ Visualiza√ß√µes do estado inicial salvas em: {output_dir}")
        return True
    
    def detect_optimal_strategy_for_medical_data(self, X, y):
        """
        Detecta estrat√©gia √≥tima mantendo TODAS as classes m√©dicas
        """
        print(f"\n" + "="*70)
        print("DETEC√á√ÉO DE ESTRAT√âGIA √ìTIMA PARA DADOS M√âDICOS")
        print("="*70)
        
        class_counts = Counter(y)
        n_samples = len(y)
        n_classes = len(class_counts)
        
        # An√°lise detalhada
        majority_class = max(class_counts.values())
        minority_class = min(class_counts.values())
        imbalance_ratio = majority_class / minority_class
        
        # Classes cr√≠ticas (m√©dicas)
        critical_classes = {cls: count for cls, count in class_counts.items() if count < 10}
        very_critical_classes = {cls: count for cls, count in class_counts.items() if count < 5}
        
        print(f"üìä An√°lise detalhada:")
        print(f"  Amostras: {n_samples}")
        print(f"  Classes: {n_classes}")
        print(f"  Raz√£o de desbalanceamento: {imbalance_ratio:.1f}:1")
        print(f"  Classes cr√≠ticas (<10): {len(critical_classes)}")
        print(f"  Classes muito cr√≠ticas (<5): {len(very_critical_classes)}")
        
        if critical_classes:
            print(f"  Detalhes classes cr√≠ticas: {critical_classes}")
        
        # ESTRAT√âGIA ESPEC√çFICA PARA DADOS M√âDICOS
        print(f"\nüè• ESTRAT√âGIA PARA DADOS M√âDICOS:")
        print(f"  ‚ö†Ô∏è  MANTENDO TODAS AS 6 CLASSES (n√£o agrupamento)")
        
        # Sele√ß√£o de estrat√©gia baseada na medicina
        if len(very_critical_classes) > 0:
            print(f"  üö® Classes com <5 amostras detectadas")
            print(f"  üìã Estrat√©gia: SVMSMOTE + Class Weights")
            strategy = "svmsmote_conservative"
            
        elif imbalance_ratio > 30:
            print(f"  ‚öñÔ∏è  Desbalanceamento extremo detectado")
            print(f"  üìã Estrat√©gia: BorderlineSMOTE + Tomek")
            strategy = "borderline_tomek"
            
        elif imbalance_ratio > 10:
            print(f"  üìä Desbalanceamento alto detectado")
            print(f"  üìã Estrat√©gia: ADASYN")
            strategy = "adasyn"
            
        else:
            print(f"  ‚úÖ Desbalanceamento moderado")
            print(f"  üìã Estrat√©gia: SMOTE cl√°ssico")
            strategy = "smote"
        
        return strategy, {
            'imbalance_ratio': imbalance_ratio,
            'critical_classes': critical_classes,
            'very_critical_classes': very_critical_classes,
            'strategy': strategy,
            'preserve_all_classes': True
        }
    
    def apply_medical_grade_balancing(self, X, y, strategy_info):
        """
        Aplica balanceamento de grau m√©dico mantendo todas as classes
        """
        strategy = strategy_info['strategy']
        
        print(f"\nüîÑ Aplicando estrat√©gia m√©dica: {strategy}")
        print(f"  üìã Distribui√ß√£o original: {Counter(y)}")
        
        try:
            if strategy == "svmsmote_conservative":
                # Para classes muito pequenas, usar SVM-SMOTE
                print(f"  üéØ SVMSMOTE para classes cr√≠ticas")
                self.classification_balancer = SVMSMOTE(
                    k_neighbors=1,  # M√≠nimo poss√≠vel
                    m_neighbors=3,   # Reduzido
                    random_state=self.random_state
                )
                
            elif strategy == "borderline_tomek":
                # BorderlineSMOTE + limpeza com Tomek
                print(f"  üéØ BorderlineSMOTE + Tomek Links")
                from imblearn.combine import SMOTETomek
                self.classification_balancer = SMOTETomek(
                    smote=BorderlineSMOTE(k_neighbors=1, random_state=self.random_state),
                    random_state=self.random_state
                )
                
            elif strategy == "adasyn":
                # ADASYN adaptativo
                print(f"  üéØ ADASYN adaptativo")
                self.classification_balancer = ADASYN(
                    n_neighbors=1,  # Reduzido para classes pequenas
                    random_state=self.random_state
                )
                
            else:
                # SMOTE com configura√ß√£o conservadora
                print(f"  üéØ SMOTE conservador")
                min_samples = min(Counter(y).values())
                k_neighbors = max(1, min(2, min_samples - 1))
                self.classification_balancer = SMOTE(
                    k_neighbors=k_neighbors,
                    random_state=self.random_state
                )
            
            # Aplicar balanceamento
            X_balanced, y_balanced = self.classification_balancer.fit_resample(X, y)
            
            print(f"  üìã Distribui√ß√£o balanceada: {Counter(y_balanced)}")
            print(f"  ‚úÖ Balanceamento aplicado: {X.shape} ‚Üí {X_balanced.shape}")
            
            return X_balanced, y_balanced, True
            
        except Exception as e:
            print(f"  ‚ùå Erro no balanceamento: {e}")
            print(f"  üîÑ Fallback: Usando class weights (sem resampling)")
            
            # Fallback: apenas usar class weights
            return X, y, False
    
    def create_after_visualizations(self, X_before, y_before, X_after, y_after, 
                                   creat_before=None, creat_after=None,
                                   tfg_before=None, tfg_after=None,
                                   balancing_applied=True,
                                   output_dir='plots/preprocessing'):
        """
        Cria visualiza√ß√µes comparativas ANTES vs DEPOIS do pr√©-processamento
        """
        print(f"\n" + "="*70)
        print("GERANDO VISUALIZA√á√ïES COMPARATIVAS - ANTES vs DEPOIS")
        print("="*70)
        
        # 1. Compara√ß√£o de classifica√ß√£o
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('COMPARA√á√ÉO: ANTES vs DEPOIS do Pr√©-processamento', fontsize=16, fontweight='bold')
        
        # Distribui√ß√£o de classes - ANTES
        before_counts = Counter(y_before)
        classes = sorted(before_counts.keys())
        before_values = [before_counts[cls] for cls in classes]
        
        bars1 = axes[0, 0].bar(range(len(classes)), before_values, 
                              color='lightcoral', alpha=0.7, edgecolor='black')
        axes[0, 0].set_title('ANTES - Distribui√ß√£o de Classes')
        axes[0, 0].set_ylabel('N√∫mero de Amostras')
        axes[0, 0].set_xticks(range(len(classes)))
        axes[0, 0].set_xticklabels([f'G{cls+1}' for cls in classes])
        
        # Destacar classes cr√≠ticas
        for i, (bar, count) in enumerate(zip(bars1, before_values)):
            if count < 10:
                bar.set_color('red')
                bar.set_alpha(0.8)
            axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                           str(count), ha='center', va='bottom', fontweight='bold')
        axes[0, 0].grid(True, alpha=0.3)
        
        # Distribui√ß√£o de classes - DEPOIS
        after_counts = Counter(y_after)
        after_values = [after_counts.get(cls, 0) for cls in classes]
        
        bars2 = axes[0, 1].bar(range(len(classes)), after_values, 
                              color='lightgreen', alpha=0.7, edgecolor='black')
        axes[0, 1].set_title('DEPOIS - Distribui√ß√£o de Classes')
        axes[0, 1].set_ylabel('N√∫mero de Amostras')
        axes[0, 1].set_xticks(range(len(classes)))
        axes[0, 1].set_xticklabels([f'G{cls+1}' for cls in classes])
        
        for i, (bar, count) in enumerate(zip(bars2, after_values)):
            axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                           str(count), ha='center', va='bottom', fontweight='bold')
        axes[0, 1].grid(True, alpha=0.3)
        
        # Compara√ß√£o lado a lado
        x = np.arange(len(classes))
        width = 0.35
        
        axes[0, 2].bar(x - width/2, before_values, width, label='Antes', 
                      color='lightcoral', alpha=0.7)
        axes[0, 2].bar(x + width/2, after_values, width, label='Depois', 
                      color='lightgreen', alpha=0.7)
        axes[0, 2].set_title('Compara√ß√£o Direta')
        axes[0, 2].set_ylabel('N√∫mero de Amostras')
        axes[0, 2].set_xticks(x)
        axes[0, 2].set_xticklabels([f'G{cls+1}' for cls in classes])
        axes[0, 2].legend()
        axes[0, 2].grid(True, alpha=0.3)
        
        # Escala log para melhor visualiza√ß√£o
        axes[1, 0].bar(range(len(classes)), before_values, 
                      color='lightcoral', alpha=0.7, edgecolor='black')
        axes[1, 0].set_yscale('log')
        axes[1, 0].set_title('ANTES (Escala Log)')
        axes[1, 0].set_ylabel('Amostras (log)')
        axes[1, 0].set_xticks(range(len(classes)))
        axes[1, 0].set_xticklabels([f'G{cls+1}' for cls in classes])
        axes[1, 0].grid(True, alpha=0.3)
        
        axes[1, 1].bar(range(len(classes)), after_values, 
                      color='lightgreen', alpha=0.7, edgecolor='black')
        axes[1, 1].set_yscale('log')
        axes[1, 1].set_title('DEPOIS (Escala Log)')
        axes[1, 1].set_ylabel('Amostras (log)')
        axes[1, 1].set_xticks(range(len(classes)))
        axes[1, 1].set_xticklabels([f'G{cls+1}' for cls in classes])
        axes[1, 1].grid(True, alpha=0.3)
        
        # M√©tricas de melhoria
        before_ratio = max(before_values) / min(before_values) if min(before_values) > 0 else float('inf')
        after_ratio = max(after_values) / min(after_values) if min(after_values) > 0 else float('inf')
        
        metrics_text = f"""M√âTRICAS DE MELHORIA:

Balanceamento Aplicado: {"Sim" if balancing_applied else "N√£o"}

ANTES:
‚Ä¢ Total: {sum(before_values)} amostras
‚Ä¢ Raz√£o: {before_ratio:.1f}:1
‚Ä¢ Classes <10: {sum(1 for v in before_values if v < 10)}

DEPOIS:
‚Ä¢ Total: {sum(after_values)} amostras
‚Ä¢ Raz√£o: {after_ratio:.1f}:1
‚Ä¢ Melhoria: {((before_ratio - after_ratio) / before_ratio * 100):.1f}%

PRESERVA√á√ÉO:
‚Ä¢ Todas as 6 classes mantidas ‚úÖ
‚Ä¢ Sem agrupamento m√©dico ‚úÖ
"""
        
        axes[1, 2].text(0.05, 0.95, metrics_text, transform=axes[1, 2].transAxes,
                        fontsize=10, verticalalignment='top', 
                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        axes[1, 2].set_xlim(0, 1)
        axes[1, 2].set_ylim(0, 1)
        axes[1, 2].axis('off')
        axes[1, 2].set_title('Resumo das Melhorias')
        
        plt.tight_layout()
        plt.savefig(f'{output_dir}/02_before_after_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # 2. An√°lise das vari√°veis de regress√£o (se dispon√≠veis)
        if creat_before is not None and tfg_before is not None:
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('Compara√ß√£o: Vari√°veis de Regress√£o ANTES vs DEPOIS', fontsize=16, fontweight='bold')
            
            # CREATININA
            axes[0, 0].hist(creat_before, bins=20, alpha=0.7, color='lightcoral', 
                           label='Antes', edgecolor='black')
            if creat_after is not None and balancing_applied:
                axes[0, 0].hist(creat_after, bins=20, alpha=0.5, color='lightgreen', 
                               label='Depois', edgecolor='black')
            axes[0, 0].set_title('Distribui√ß√£o da Creatinina')
            axes[0, 0].set_xlabel('Creatinina (mg/dL)')
            axes[0, 0].set_ylabel('Frequ√™ncia')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
            
            # TFG
            axes[0, 1].hist(tfg_before, bins=20, alpha=0.7, color='lightblue', 
                           label='Antes', edgecolor='black')
            if tfg_after is not None and balancing_applied:
                axes[0, 1].hist(tfg_after, bins=20, alpha=0.5, color='lightgreen', 
                               label='Depois', edgecolor='black')
            axes[0, 1].set_title('Distribui√ß√£o da TFG')
            axes[0, 1].set_xlabel('TFG (mL/min/1.73m¬≤)')
            axes[0, 1].set_ylabel('Frequ√™ncia')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
            
            # Correla√ß√£o ANTES
            axes[1, 0].scatter(creat_before, tfg_before, alpha=0.6, color='red')
            corr_before = np.corrcoef(creat_before, tfg_before)[0, 1]
            axes[1, 0].set_title(f'ANTES - Correla√ß√£o: {corr_before:.3f}')
            axes[1, 0].set_xlabel('Creatinina (mg/dL)')
            axes[1, 0].set_ylabel('TFG (mL/min/1.73m¬≤)')
            axes[1, 0].grid(True, alpha=0.3)
            
            # Correla√ß√£o DEPOIS
            if creat_after is not None and tfg_after is not None and balancing_applied:
                axes[1, 1].scatter(creat_after, tfg_after, alpha=0.6, color='green')
                corr_after = np.corrcoef(creat_after, tfg_after)[0, 1]
                axes[1, 1].set_title(f'DEPOIS - Correla√ß√£o: {corr_after:.3f}')
            else:
                axes[1, 1].scatter(creat_before, tfg_before, alpha=0.6, color='red')
                axes[1, 1].set_title('DEPOIS - Sem Balanceamento')
            
            axes[1, 1].set_xlabel('Creatinina (mg/dL)')
            axes[1, 1].set_ylabel('TFG (mL/min/1.73m¬≤)')
            axes[1, 1].grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig(f'{output_dir}/03_regression_variables_comparison.png', dpi=300, bbox_inches='tight')
            plt.show()
        
        print(f"‚úÖ Visualiza√ß√µes comparativas salvas em: {output_dir}")
        
        # Imprimir m√©tricas de melhoria
        print(f"\nüìä M√âTRICAS DE MELHORIA:")
        print(f"   Balanceamento aplicado: {'Sim' if balancing_applied else 'N√£o'}")
        print(f"   Amostras antes: {sum(before_values)}")
        print(f"   Amostras depois: {sum(after_values)}")
        print(f"   Raz√£o antes: {before_ratio:.1f}:1")
        print(f"   Raz√£o depois: {after_ratio:.1f}:1")
        if before_ratio != float('inf') and after_ratio != float('inf'):
            improvement = ((before_ratio - after_ratio) / before_ratio) * 100
            print(f"   Melhoria no balanceamento: {improvement:.1f}%")
        print(f"   ‚úÖ Todas as 6 classes preservadas (cr√≠tico para medicina)")
        
        return True
    
    def fit_transform_medical_data(self, data_path):
        """
        Pipeline completo de pr√©-processamento de grau m√©dico
        """
        print("=" * 80)
        print("PIPELINE DE PR√â-PROCESSAMENTO DE GRAU M√âDICO - DRC")
        print("=" * 80)
        
        # 1. Carregar dados
        df = pd.read_csv(data_path, sep=';', encoding='utf-8')
        print(f"üìä Dataset carregado: {df.shape}")
        
        # 2. An√°lise do estado inicial
        initial_analysis = self.analyze_initial_state(df)
        
        # 3. Visualiza√ß√µes do estado inicial
        self.create_before_visualizations(df, 'plots/preprocessing_medical')
        
        # 4. Preparar dados
        print(f"\n" + "="*50)
        print("PREPARA√á√ÉO DOS DADOS")
        print("="*50)
        
        # Corrigir formato decimal
        decimal_columns = ['CREATININA', 'C. PES', 'C.PANT', 'UREIA', 'HDL', 'LDL']
        for col in decimal_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(
                    df[col].astype(str).str.replace(',', '.'), 
                    errors='coerce'
                )
                print(f"  ‚úÖ Corrigido formato: {col}")
        
        # Extrair features de entrada
        available_features = [f for f in self.input_features if f in df.columns]
        print(f"  üìã Features dispon√≠veis: {len(available_features)}/{len(self.input_features)}")
        
        X = df[available_features].copy()
        
        # Encoding de vari√°veis categ√≥ricas
        categorical_features = X.select_dtypes(include=['object']).columns
        for feature in categorical_features:
            le = LabelEncoder()
            X[feature] = le.fit_transform(X[feature].astype(str))
            self.label_encoders[feature] = le
            print(f"  üî§ Codificado: {feature}")
        
        # Normaliza√ß√£o
        self.scaler = RobustScaler()
        X_scaled = pd.DataFrame(
            self.scaler.fit_transform(X),
            columns=X.columns,
            index=X.index
        )
        print(f"  üìè Normaliza√ß√£o aplicada (RobustScaler)")
        
        # Preparar targets
        targets = {}
        
        # CREATININA (regress√£o)
        if 'CREATININA' in df.columns:
            targets['creatinina'] = df['CREATININA'].values
            print(f"  üéØ Target CREATININA preparado: {len(targets['creatinina'])} amostras")
        
        # TFG (regress√£o)
        if 'TFG' in df.columns:
            targets['tfg'] = df['TFG'].values
            print(f"  üéØ Target TFG preparado: {len(targets['tfg'])} amostras")
        
        # TFG_Classification (classifica√ß√£o)
        if 'TFG_Classification' in df.columns:
            self.target_encoder = LabelEncoder()
            y_classification = self.target_encoder.fit_transform(df['TFG_Classification'])
            self.target_names = self.target_encoder.classes_
            
            # 5. Detectar estrat√©gia √≥tima
            strategy, strategy_info = self.detect_optimal_strategy_for_medical_data(
                X_scaled.values, y_classification
            )
            
            # 6. Aplicar balanceamento m√©dico
            X_balanced, y_balanced, balancing_applied = self.apply_medical_grade_balancing(
                X_scaled.values, y_classification, strategy_info
            )
            
            targets['classification'] = {
                'X_original': X_scaled.values,
                'y_original': y_classification,
                'X_balanced': X_balanced,
                'y_balanced': y_balanced,
                'balancing_applied': balancing_applied,
                'target_names': self.target_names,
                'strategy_info': strategy_info
            }
            
            print(f"  üéØ Target TFG_Classification preparado: {len(y_classification)} ‚Üí {len(y_balanced)} amostras")
            
            # 7. Criar visualiza√ß√µes comparativas
            self.create_after_visualizations(
                X_before=X_scaled.values,
                y_before=y_classification,
                X_after=X_balanced,
                y_after=y_balanced,
                creat_before=targets.get('creatinina'),
                creat_after=targets.get('creatinina'),  # Regress√£o n√£o √© balanceada
                tfg_before=targets.get('tfg'),
                tfg_after=targets.get('tfg'),  # Regress√£o n√£o √© balanceada
                balancing_applied=balancing_applied,
                output_dir='plots/preprocessing_medical'
            )
        
        # 8. Estruturar dados processados
        processed_data = {
            'features_original': X_scaled,
            'targets': targets,
            'preprocessing_report': self.preprocessing_report,
            'feature_names': available_features,
            'scaler': self.scaler,
            'label_encoders': self.label_encoders
        }
        
        self.feature_names = available_features
        self.is_fitted = True
        
        print(f"\n" + "="*80)
        print("PR√â-PROCESSAMENTO DE GRAU M√âDICO CONCLU√çDO")
        print("="*80)
        print(f"‚úÖ An√°lise completa do estado inicial")
        print(f"‚úÖ Corre√ß√£o de problemas de formata√ß√£o")
        print(f"‚úÖ Valida√ß√£o cl√≠nica especializada")
        print(f"‚úÖ Estrat√©gia de balanceamento adaptativa")
        print(f"‚úÖ Preserva√ß√£o de TODAS as 6 classes m√©dicas")
        print(f"‚úÖ Visualiza√ß√µes comparativas detalhadas")
        print(f"‚úÖ Suporte para 3 tarefas: CREATININA + TFG + Classifica√ß√£o")
        
        return processed_data

def main():
    """
    Demonstra√ß√£o do pipeline de grau m√©dico
    """
    # Criar diret√≥rios
    os.makedirs('plots/preprocessing_medical', exist_ok=True)
    
    # Inicializar preprocessador
    preprocessor = MedicalGradeDRCPreprocessor(random_state=42)
    
    # Executar pipeline completo
    data_path = '/Users/aiacontext/PycharmProjects/jaliRNA/dataset/dataset_drc_processed.csv'
    processed_data = preprocessor.fit_transform_medical_data(data_path)
    
    print(f"\nüè• PIPELINE DE GRAU M√âDICO EXECUTADO COM SUCESSO!")
    print(f"üìä Todas as visualiza√ß√µes salvas em: plots/preprocessing_medical/")
    print(f"üéØ Dados preparados para as 3 tarefas: CREATININA + TFG + Classifica√ß√£o")

if __name__ == "__main__":
    main()